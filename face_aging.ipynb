{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# download the dataset from https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
    "\n",
    "# !wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
    "# !tar -xvf wiki_crop.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "from keras import Input, Model\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    Reshape,\n",
    "    concatenate,\n",
    "    LeakyReLU,\n",
    "    Lambda,\n",
    "    Activation,\n",
    "    UpSampling2D,\n",
    "    Dropout\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing import image\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    \"\"\"\n",
    "    Build the encoder network that encodes an image (x) to a latent vector (z)\n",
    "    or a latent vector representation.\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "    # 1st convolutional block\n",
    "    enc = Conv2D(\n",
    "        filters=32, kernel_size=5, strides=2, padding=\"same\"\n",
    "    )(input_layer)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 2nd convolutional block\n",
    "    enc = Conv2D(\n",
    "        filters=64, kernel_size=5, strides=2, padding=\"same\"\n",
    "    )(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 3rd convolutional block\n",
    "    enc = Conv2D(\n",
    "        filters=128, kernel_size=5, strides=2, padding=\"same\"\n",
    "    )(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 4th convolutional block\n",
    "    enc = Conv2D(\n",
    "        filters=256, kernel_size=5, strides=2, padding=\"same\"\n",
    "    )(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # flattening layer\n",
    "    enc = Flatten()(enc)\n",
    "\n",
    "    # 1st fully-connected Layer\n",
    "    enc = Dense(4096)(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 2nd fully-connected Layer\n",
    "    enc = Dense(100)(enc)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_layer], outputs=[enc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Build the Generator.\n",
    "    It takes a 100-dimensional vector z and generates an image with a dimension of (64, 64, 3).\n",
    "    \"\"\"\n",
    "    # define the hyperparameters\n",
    "    latent_dims = 100\n",
    "    num_classes = 6\n",
    "\n",
    "    input_z_noise = Input(shape=(latent_dims,))\n",
    "    input_label = Input(shape=(num_classes,))\n",
    "\n",
    "    # the generator will take both the noise vector and desired class label as input\n",
    "    x = concatenate([input_z_noise, input_label])\n",
    "\n",
    "    # 1st fully-connected block\n",
    "    x = Dense(2048, input_dim=latent_dims + num_classes)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # 2nd fully-connected block\n",
    "    x = Dense(256 * 8 * 8)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Reshape((8, 8, 256))(x)\n",
    "\n",
    "    # 1st upsampling block\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=128, kernel_size=5, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 2nd upsampling block\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=64, kernel_size=5, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 3rd upsampling block\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=3, kernel_size=5, padding=\"same\")(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_label_input(x):\n",
    "    \"\"\"\n",
    "    Expand label_input so that it has a shape of (32, 32, 6) and not (6,)\n",
    "    \"\"\"\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.tile(x, [1, 32, 32, 1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator network is a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Create a CNN-based Discriminator\n",
    "    \"\"\"\n",
    "    # define the hyperparameters\n",
    "    input_shape = (64, 64, 3)\n",
    "    label_shape = (6,)\n",
    "    image_input = Input(shape=input_shape)\n",
    "    label_input = Input(shape=label_shape)\n",
    "\n",
    "    # 1st convolutional block for the image input\n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(image_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    label_input1 = Lambda(expand_label_input)(label_input)\n",
    "    x = concatenate([x, label_input1], axis=3)\n",
    "\n",
    "    # 1st convolutional block\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 2nd convolutional block\n",
    "    x = Conv2D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 3rd convolutional block\n",
    "    x = Conv2D(512, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # flattening layer\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # 1st fully-connected block\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[image_input, label_input], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fr_model(input_shape):\n",
    "    \"\"\"\n",
    "    Function to build the face recognition model.\n",
    "    \"\"\"\n",
    "    # using ResNet of 164 layers because it has excellent performance\n",
    "    resnet_model = InceptionResNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape,\n",
    "        pooling=\"avg\"\n",
    "    )\n",
    "    image_input = resnet_model.input\n",
    "    out = Dense(128)(x)\n",
    "    embedder_model = Model(inputs=[image_input], outputs=[out])\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = resnet_model.layers[-1].output\n",
    "    x = embedder_model(input_layer)\n",
    "    output = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fr_combined_network(encoder, generator, fr_model):\n",
    "    \"\"\"\n",
    "    Function to build the face recognition combined network.\n",
    "    \"\"\"\n",
    "    # freeze the weights of the model responsible for facial recognition\n",
    "    fr_model.trainable = False\n",
    "\n",
    "    input_image = Input(shape=(64, 64, 3))\n",
    "    input_label = Input(shape=(6,))\n",
    "\n",
    "    # encode the image to a latent vector representation\n",
    "    latent0 = encoder(input_image)\n",
    "\n",
    "    # generate artificial images\n",
    "    gen_images = generator([latent0, input_label])\n",
    "\n",
    "    # resize the images generated by the generator for input to the model responsible for facial recognition\n",
    "    resized_images = Lambda(\n",
    "        lambda x: K.resize_images(\n",
    "            gen_images,\n",
    "            height_factor=2,\n",
    "            width_factor=2,\n",
    "            data_format=\"channels_last\"\n",
    "        )\n",
    "    )(gen_images)\n",
    "    embeddings = fr_model(resized_images)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions\n",
    "\"\"\"\n",
    "\n",
    "def build_image_resizer():\n",
    "    \"\"\"\n",
    "    Function to resize the images from a shape of (64, 64, 3) to a shape of (192, 192, 3)\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "    factor = int(192 / 64)\n",
    "\n",
    "    resized_images = Lambda(\n",
    "        lambda x: K.resize_images(\n",
    "            x,\n",
    "            height_factor=factor,\n",
    "            width_factor=factor,\n",
    "            data_format=\"channels_last\"\n",
    "        )\n",
    "    )(input_layer)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_layer], outputs=[resized_images])\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_age(taken, dob):\n",
    "    \"\"\"\n",
    "    Function to calculate the age of the person from the serial date number and the year the photo was taken.\n",
    "    \"\"\"\n",
    "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
    "\n",
    "    if birth.month < 7:\n",
    "        return taken - birth.year\n",
    "    else:\n",
    "        return taken - birth.year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(wiki_dir, dataset='wiki'):\n",
    "    \"\"\"\n",
    "    Function to retrieve images and their corresponding ages from the directory\n",
    "    \"\"\"\n",
    "    # load the .mat file\n",
    "    meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
    "\n",
    "    # load the list of all files\n",
    "    full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
    "\n",
    "    # list of Matlab serial date numbers\n",
    "    dob = meta[dataset][0, 0][\"dob\"][0]\n",
    "\n",
    "    # list of years when photo was taken\n",
    "    photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]\n",
    "\n",
    "    # calculate age for all dobs\n",
    "    age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
    "\n",
    "    # create a list of tuples containing a pair of an image path and age\n",
    "    images = []\n",
    "    age_list = []\n",
    "    for index, image_path in enumerate(full_path):\n",
    "        images.append(image_path[0])\n",
    "        age_list.append(age[index])\n",
    "\n",
    "    # return a list of all images and respective age\n",
    "    return images, age_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the age numerical value to the age category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_category(age_list):\n",
    "    \"\"\"\n",
    "    Functio to convert the age's numerical value to a category.\n",
    "    \n",
    "    The ranges are arbitrarily chosen and can be changed later.\n",
    "    \"\"\"\n",
    "    print(f\"age_list length: {len(age_list)}\")\n",
    "\n",
    "    age_list_cat = []\n",
    "\n",
    "    for age in age_list:\n",
    "        if 0 < age <= 18:\n",
    "            cat = 0\n",
    "        elif 18 < age <= 29:\n",
    "            cat = 1\n",
    "        elif 29 < age <= 39:\n",
    "            cat = 2\n",
    "        elif 39 < age <= 49:\n",
    "            cat = 3\n",
    "        elif 49 < age <= 59:\n",
    "            cat = 4\n",
    "        elif age >= 60:\n",
    "            cat = 5\n",
    "        age_list_cat.append(cat)\n",
    "\n",
    "    return age_list_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir, image_paths, image_shape):\n",
    "    \"\"\"\n",
    "    Function to load all images and create an ndarray containing all images.\n",
    "    \"\"\"\n",
    "    images = None\n",
    "    for ind, image_path in enumerate(image_paths):\n",
    "        print(f\"index: {ind} and image path: {image_path}\")\n",
    "        try:\n",
    "            # load the image\n",
    "            loaded_image = image.load_img(\n",
    "                os.path.join(data_dir, image_path),\n",
    "                target_size=image_shape\n",
    "            )\n",
    "\n",
    "            # convert the PIL image to a NumPy ndarray\n",
    "            loaded_image = image.img_to_array(loaded_image)\n",
    "\n",
    "            # add another (batch) dimension\n",
    "            loaded_image = np.expand_dims(loaded_image, axis=0)\n",
    "\n",
    "            # concatenate all the images into an array\n",
    "            if images is None:\n",
    "                images = loaded_image\n",
    "            else:\n",
    "                images = np.concatenate(\n",
    "                    [images, loaded_image],\n",
    "                    axis=0\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e} at index {ind}\")\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance: https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "\n",
    "def write_log(callback, name, value, batch_no):\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = value\n",
    "    summary_value.tag = name\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()\n",
    "\n",
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an RGB image to the directory\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the training hyperparameters\n",
    "\"\"\"\n",
    "data_dir = \"./data\"\n",
    "wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
    "epochs = 500\n",
    "batch_size = 2\n",
    "image_shape = (64, 64, 3)\n",
    "z_shape = 100\n",
    "TRAIN_GAN = True\n",
    "TRAIN_ENCODER = False\n",
    "TRAIN_GAN_WITH_FR = False\n",
    "fr_image_shape = (192, 192, 3)\n",
    "\n",
    "\"\"\"\n",
    "Define the optimizers\n",
    "\"\"\"\n",
    "# optimizer for the discriminator\n",
    "dis_optimizer = Adam(\n",
    "    lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8\n",
    ")\n",
    "# optimizer for the generator\n",
    "gen_optimizer = Adam(\n",
    "    lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8\n",
    ")\n",
    "# optimizer for the GAN network\n",
    "adversarial_optimizer = Adam(\n",
    "    lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Build and compile the networks\n",
    "\"\"\"\n",
    "# the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(\n",
    "    loss=[\"binary_crossentropy\"],\n",
    "    optimizer=dis_optimizer\n",
    ")\n",
    "discriminator.trainable = False\n",
    "\n",
    "# the generator\n",
    "generator = build_generator()\n",
    "generator.compile(\n",
    "    loss=[\"binary_crossentropy\"],\n",
    "    optimizer=gen_optimizer\n",
    ")\n",
    "\n",
    "# the GAN\n",
    "input_z_noise = Input(shape=(100,))\n",
    "input_label = Input(shape=(6,))\n",
    "recons_images = generator([input_z_noise, input_label])\n",
    "valid = discriminator([recons_images, input_label])\n",
    "adversarial_model = Model(\n",
    "    inputs=[input_z_noise, input_label],\n",
    "    outputs=[valid]\n",
    ")\n",
    "adversarial_model.compile(\n",
    "    loss=[\"binary_crossentropy\"],\n",
    "    optimizer=gen_optimizer\n",
    ")\n",
    "\n",
    "# initialize the tensorboard\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{time.time()}\")\n",
    "tensorboard.set_model(generator)\n",
    "tensorboard.set_model(discriminator)\n",
    "\n",
    "# load the dataset\n",
    "images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
    "print(f\"Number of images = {len(images)}\")\n",
    "print(f\"age_list size = {len(age_list)}\")\n",
    "\n",
    "# convert the numeric age to categorical age\n",
    "age_cat = np.array(age_to_category(age_list))\n",
    "final_age_cat = np.reshape(age_cat, [len(age_cat), 1])\n",
    "\n",
    "# get the unique classes by converting the list to a set\n",
    "classes = len(set(age_cat))\n",
    "y = to_categorical(final_age_cat, num_classes=len(set(age_cat)))\n",
    "\n",
    "loaded_images = load_images(\n",
    "    wiki_dir,\n",
    "    images,\n",
    "    (image_shape[0], image_shape[1])\n",
    ")\n",
    "\n",
    "# label smoothing\n",
    "real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
    "fake_labels = np.zeros((batch_size, 1), dtype=np.float32) * 0.1\n",
    "\n",
    "\"\"\"\n",
    "Train the generator and the discriminator\n",
    "\"\"\"\n",
    "if TRAIN_GAN:\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch = {epoch}\")\n",
    "\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "\n",
    "        number_of_batches = int(len(loaded_images) / batch_size)\n",
    "        print(f\"Number of batches = {number_of_batches}\")\n",
    "        for index in range(number_of_batches):\n",
    "            print(f\"Batch = {index + 1}\")\n",
    "\n",
    "            images_batch = loaded_images[\n",
    "                index * batch_size: (index + 1) * batch_size\n",
    "            ]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            # generate the noise vector\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "\n",
    "            \"\"\"\n",
    "            Train the discriminator network\n",
    "            \"\"\"\n",
    "\n",
    "            # generate fake images\n",
    "            initial_recon_images = generator.predict_on_batch(\n",
    "                [z_noise, y_batch]\n",
    "            )\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(\n",
    "                [images_batch, y_batch],\n",
    "                real_labels\n",
    "            )\n",
    "            d_loss_fake = discriminator.train_on_batch(\n",
    "                [initial_recon_images, y_batch],\n",
    "                fake_labels\n",
    "            )\n",
    "\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print(f\"Discriminator loss = {d_loss}\")\n",
    "\n",
    "            \"\"\"\n",
    "            Train the generator network\n",
    "            \"\"\"\n",
    "\n",
    "            # generate the noise vector\n",
    "            z_noise2 = np.random.normal(\n",
    "                0,\n",
    "                1,\n",
    "                size=(batch_size, z_shape)\n",
    "            )\n",
    "\n",
    "            # generate the labels for the second input of the generator\n",
    "            random_labels = np.random.randint(\n",
    "                0,\n",
    "                6,\n",
    "                batch_size\n",
    "            ).reshape(-1, 1)\n",
    "            random_labels = to_categorical(random_labels, 6)\n",
    "\n",
    "            g_loss = adversarial_model.train_on_batch(\n",
    "                [z_noise2, random_labels],\n",
    "                [1] * batch_size\n",
    "            )\n",
    "\n",
    "            print(f\"Generator loss = {g_loss}\")\n",
    "\n",
    "            gen_losses.append(g_loss)\n",
    "            dis_losses.append(d_loss)\n",
    "\n",
    "        # write the losses to Tensorboard\n",
    "        write_log(tensorboard, \"g_loss\", np.mean(gen_losses), epoch)\n",
    "        write_log(tensorboard, \"d_loss\", np.mean(dis_losses), epoch)\n",
    "\n",
    "        \"\"\"\n",
    "        Generate images after every 10th epoch\n",
    "        \"\"\"\n",
    "        if epoch % 10 == 0:\n",
    "            images_batch = loaded_images[0: batch_size]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[0: batch_size]\n",
    "            z_noise = np.random.normal(\n",
    "                0,\n",
    "                1,\n",
    "                size=(batch_size, z_shape)\n",
    "            )\n",
    "\n",
    "            gen_images = generator.predict_on_batch(\n",
    "                [z_noise, y_batch]\n",
    "            )\n",
    "\n",
    "            for ind, img in enumerate(gen_images[:5]):\n",
    "                save_rgb_img(\n",
    "                    img, path=f\"./results/img_{epoch}_{ind}.png\"\n",
    "                )\n",
    "\n",
    "    # save the trained networks\n",
    "    try:\n",
    "        generator.save_weights(\"generator.h5\")\n",
    "        discriminator.save_weights(\"discriminator.h5\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} encountered\")\n",
    "\n",
    "\"\"\"\n",
    "Train the encoder\n",
    "\"\"\"\n",
    "\n",
    "if TRAIN_ENCODER:\n",
    "    # build and compile the encoder\n",
    "    encoder = build_encoder()\n",
    "    encoder.compile(\n",
    "        loss=euclidean_distance_loss,\n",
    "        optimizer=\"adam\"\n",
    "    )\n",
    "\n",
    "    # load the generator's weights\n",
    "    try:\n",
    "        generator.load_weights(\"generator.h5\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} encountered\")\n",
    "\n",
    "    z_i = np.random.normal(0, 1, size=(5000, z_shape))\n",
    "\n",
    "    y = np.random.randint(\n",
    "        low=0,\n",
    "        high=6,\n",
    "        size=(5000,),\n",
    "        dtype=np.int64\n",
    "    )\n",
    "    # get the unique classes by converting the list to a set\n",
    "    num_classes = len(set(y))\n",
    "    y = np.reshape(np.array(y), [len(y), 1])\n",
    "    y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch = {epoch}\")\n",
    "\n",
    "        encoder_losses = []\n",
    "        number_of_batches = int(z_i.shape[0] / batch_size)\n",
    "        print(f\"Number of batches = {number_of_batches}\")\n",
    "        for index in range(number_of_batches):\n",
    "            print(f\"Batch = {index + 1}\")\n",
    "\n",
    "            z_batch = z_i[\n",
    "                index * batch_size: (index + 1) * batch_size\n",
    "            ]\n",
    "            y_batch = y[\n",
    "                index * batch_size: (index + 1) * batch_size\n",
    "            ]\n",
    "\n",
    "            generated_images = generator.predict_on_batch(\n",
    "                [z_batch, y_batch]\n",
    "            )\n",
    "\n",
    "            # train the encoder model\n",
    "            encoder_loss = encoder.train_on_batch(\n",
    "                generated_images,\n",
    "                z_batch\n",
    "            )\n",
    "            print(f\"Encoder loss = {encoder_loss}\")\n",
    "\n",
    "            encoder_losses.append(encoder_loss)\n",
    "\n",
    "        # write the encoder loss to Tensorboard\n",
    "        write_log(\n",
    "            tensorboard,\n",
    "            \"encoder_loss\",\n",
    "            np.mean(encoder_losses),\n",
    "            epoch\n",
    "        )\n",
    "\n",
    "    # save the encoder for further use\n",
    "    encoder.save_weights(\"encoder.h5\")\n",
    "\n",
    "\"\"\"\n",
    "Optimize the encoder and the generator\n",
    "\"\"\"\n",
    "if TRAIN_GAN_WITH_FR:\n",
    "\n",
    "    # load the encoder network\n",
    "    encoder = build_encoder()\n",
    "    encoder.load_weights(\"encoder.h5\")\n",
    "\n",
    "    # load the generator network\n",
    "    generator.load_weights(\"generator.h5\")\n",
    "\n",
    "    image_resizer = build_image_resizer()\n",
    "    image_resizer.compile(\n",
    "        loss=[\"binary_crossentropy\"],\n",
    "        optimizer=\"adam\"\n",
    "    )\n",
    "\n",
    "    # face recognition model\n",
    "    fr_model = build_fr_model(input_shape=fr_image_shape)\n",
    "    fr_model.compile(\n",
    "        loss=[\"binary_crossentropy\"],\n",
    "        optimizer=\"adam\"\n",
    "    )\n",
    "\n",
    "    # freeze the face recognition model's weights\n",
    "    fr_model.trainable = False\n",
    "\n",
    "    # input layers\n",
    "    input_image = Input(shape=(64, 64, 3))\n",
    "    input_label = Input(shape=(6,))\n",
    "\n",
    "    # use the encoder and, then, the generator from its output\n",
    "    latent0 = encoder(input_image)\n",
    "    gen_images = generator([latent0, input_label])\n",
    "\n",
    "    # resize images to the desired shape\n",
    "    resized_images = Lambda(\n",
    "        lambda x: K.resize_images(\n",
    "            gen_images,\n",
    "            height_factor=3,\n",
    "            width_factor=3,\n",
    "            data_format=\"channels_last\"\n",
    "        )\n",
    "    )(gen_images)\n",
    "    embeddings = fr_model(resized_images)\n",
    "\n",
    "    # create a GAN and specify its inputs and outputs\n",
    "    fr_adversarial_model = Model(\n",
    "        inputs=[input_image, input_label],\n",
    "        outputs=[embeddings]\n",
    "    )\n",
    "\n",
    "    # compile the GAN\n",
    "    fr_adversarial_model.compile(\n",
    "        loss=euclidean_distance_loss,\n",
    "        optimizer=adversarial_optimizer\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch = {epoch}\")\n",
    "\n",
    "        reconstruction_losses = []\n",
    "\n",
    "        number_of_batches = int(len(loaded_images) / batch_size)\n",
    "        print(f\"Number of batches = {number_of_batches}\")\n",
    "        for index in range(number_of_batches):\n",
    "            print(f\"Batch = {index + 1}\")\n",
    "\n",
    "            images_batch = loaded_images[\n",
    "                index * batch_size:(index + 1) * batch_size\n",
    "            ]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            images_batch_resized = image_resizer.predict_on_batch(\n",
    "                images_batch\n",
    "            )\n",
    "\n",
    "            real_embeddings = fr_model.predict_on_batch(\n",
    "                images_batch_resized\n",
    "            )\n",
    "\n",
    "            reconstruction_loss = fr_adversarial_model.train_on_batch(\n",
    "                [images_batch, y_batch],\n",
    "                real_embeddings\n",
    "            )\n",
    "\n",
    "            print(f\"Reconstruction loss = {reconstruction_loss}\")\n",
    "            reconstruction_losses.append(reconstruction_loss)\n",
    "\n",
    "        # write the reconstruction loss to Tensorboard\n",
    "        write_log(\n",
    "            tensorboard,\n",
    "            \"reconstruction_loss\",\n",
    "            np.mean(reconstruction_losses),\n",
    "            epoch\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        Generate images\n",
    "        \"\"\"\n",
    "        if epoch % 10 == 0:\n",
    "            images_batch = loaded_images[0:batch_size]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[0: batch_size]\n",
    "            z_noise = np.random.normal(\n",
    "                0, 1, size=(batch_size, z_shape)\n",
    "            )\n",
    "\n",
    "            gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "\n",
    "            for ind, img in enumerate(gen_images[:5]):\n",
    "                save_rgb_img(img, path=f\"./results/img_opt_{epoch}_{ind}.png\")\n",
    "\n",
    "    # save the improved weights for both models\n",
    "    generator.save_weights(\"generator_optimized.h5\")\n",
    "    encoder.save_weights(\"encoder_optimized.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
